---
title: "Lab3"
author: "Margaret Connor"
date: "1/30/2019"
output: html_document
---
## Exploring the Data

1. Import and read the csv data file.
```{r}
wiscData <-read.csv('/Users/margaretconnor/NetBeansProjects/Rdata/wisc_bc_data.csv', 
                     stringsAsFactors = FALSE);
```
2.Examine the structure of the wbcd data frame.
```{r}
str(wiscData)
```
3. How to drop the id feature from the analysis? Why to remove it?
```{r}
wiscData<-wiscData[-1]
```
4. Find the target variable. How many levels this variable have?
The target data has 2 levels as Factors B and M
```{r}
table(wiscData$diagnosis)
```
5. Transform this nominal variable to factor and give its levels a better names. What are their correspondentâ€™s percentage with 1 decimal place?
```{r}
levels(wiscData$diagnosis) <- c("Benign","Malignant")
round(prop.table(table(wiscData$diagnosis))*100, digits = 1)
```
6. Find the summary of the following 3 features: radius_mean, area_mean, and the smoothness_mean.
```{r}
summary(wiscData[c("radius_mean","area_mean","smoothness_mean")])
```
7. Looking at the features side-by-side, do you notice anything problematic about the values?

## Exploring the Data
8. Create the normalize() function and check if it work correctly using a vector of numbers before applying this function to the whole data.
```{r}
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)));
}
normalize(c(1, 2, 3, 4, 5))
normalize(c(10, 20, 30, 40, 50))
```
9. To apply the normalize() function to the whole data, we can use the lapply() function that takes a list and applies a specified function to each list element. As a data frame is a list of equal-length vectors, we can use lapply() to apply normalize() to each feature in the data frame. The final step is to convert the list returned by lapply() to a data frame, using the as.data.frame() function. Write the code of this process and rename the new data wbcd_n.
```{r}
wbcd_n <- as.data.frame(lapply(wiscData[2:31], normalize));
```
10. How to check if the normalization is working?
```{r}
summary(wbcd_n$area_mean);
```

## Data preparation - creating training and test datasets 
In the absence of new unlabeled data, we can simulate the scenario of testing new unlabeled data by dividing our data into two portions: a training dataset that will be used to build the k-NN model and a test dataset that will be used to estimate the predictive accuracy of the model. We will use the first 469 records for the training dataset and the remaining 100 to simulate new patients. 
11. Create those training and test sets named wbcd_train and wbcd_test.
```{r}
wbcd_train <- wbcd_n[1:469, ]
wbcd_test <- wbcd_n[470:569, ]
```
12. Can you store its correspondents target variable in 2 separate vectors? Name them wbcd_train_labels and wbcd_test_labels.
```{r}
wbcd_train_labels <- wiscData[1:469, 1]
wbcd_test_labels <- wiscData[470:569, 1]
```

#Training a model on the data
Equipped with our training data and labels vector, we are now ready to classify our unknown records.

For the k-NN algorithm, the training phase actually involves no model building; the process of training a lazy learner like k-NN simply involves storing the input data in a structured format. 

To classify our test instances, we will use a k-NN implementation from the class package, which provides a set of basic R functions for classification. 

13. How to install the class package in R?
```{r, echo=TRUE}
#install.packages("class");
library(class);

#install.packages(class);
library(class);
```
14. Find k.
As our training data includes 469 instances, we will try k = 21, an odd number roughly equal to the square root of 469. With a two-category outcome, using an odd number eliminates the chance of ending with a tie vote.

15. Use the knn() function from the class package to classify the test data. Name the result vector wbcd_test_pred.
```{r, echo=TRUE}
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
                      cl = wbcd_train_labels, k=21);
```

# Evaluating model performance
The next step of the process is to evaluate how well the predicted classes in the **wbcd_ test_pred** vector matches up with the known values in the **wbcd_test_labels** vector. 

16. How to compare **wbcd_ test_pred** vector to **wbcd_test_labels**?
**Tip**: Those are 2 categorical variables, how to study the relationship of two categorical variables?

```{r, echo=TRUE}

# load the "gmodels" library
library(gmodels)

# Create the cross tabulation of predicted vs. actual
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
           prop.chisq=FALSE)
```

17. What is accuracy of this model?

A total of 2 out of 100, or 2 percent of masses were incorrectly classified by the k-NN approach that means an accuracy of 98 percent.


18. Discuss and explain the results of using this model by looking into the false negative and the false positive numbers.

The cell percentages in the table indicate the proportion of values that fall into four categories: the true negative, the true positive, the false negative and the false positive.

* The top-left cell indicates the **true negative** results. These 61 of 100 values are cases where the mass was benign and the k-NN algorithm correctly identified it as such. 

* The bottom-right cell indicates the **true positive** results, where the classifier and the clinically determined label agree that the mass is malignant. A total of 37 of 100 predictions were true positives.

The cells falling on the other diagonal contain counts of examples where the k-NN approach disagreed with the true label. 

* The two examples in the lower-left cell are **false negative** results; in this case, the predicted value was benign, but the tumor was actually malignant. Errors in this direction could be extremely costly as they might lead a patient to believe that she is cancer-free, but in reality, the disease may continue to spread. 

* The top-right cell would contain the **false positive** results, if there were any. These values occur when the model classifies a mass as malignant, but in reality, it was benign. Although such errors are less dangerous than a false negative result, they should also be avoided as they could lead to additional financial burden on the health care system or additional stress for the patient as additional tests or treatment may have to be provided.



19. Is it possible to improve the performance of this model?

 While 98 percent accuracy seems impressive for a few lines of R code, we might try another iteration of the model to see whether we can improve the performance and reduce the number of values that have been incorrectly classified, particularly because the errors were dangerous false negatives. 
 
#Assignment03

###Step 1. Answer the following:

#####1. How can you improve the performance of your knn model? list two ways.
Two ways to improve our K-nn model includes rescaling the numerical features using z-score standardization and testing several K values choosing the K value that delivers the best classification performance.

#####2. Apply those 2 different ways of improvements.
 * Transformation - z-score standardization 
 
```{r}
 # use the scale() function to z-score standardize a data frame 
 wbcd_z <- as.data.frame(scale(wbcd[-1])) 

 # confirm that the transformation was applied correctly 
 summary(wbcd_z$area_mean) 

 # create training and test datasets 
 wbcd_train <- wbcd_z[1:469, ] 
 wbcd_test <- wbcd_z[470:569, ] 

 # re-classify test cases 
 wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test, 
                       cl = wbcd_train_labels, k=21) 

 # Create the cross tabulation of predicted vs. actual 
 CrossTable(x = wbcd_test_labels, y = wbcd_test_pred, 
            prop.chisq=FALSE) 


```

 Unfortunately, the results of our new transformation show a slight decline in accuracy. The instances where we had correctly classified 98 percent of examples previously, we classified only 95 percent correctly this time. Making matters worse, we did no better at classifying the dangerous false negatives. 

 * Testing alternative values of k  

```{r, echo=TRUE} 
 # try several different values of k 
 wbcd_train <- wbcd_n[1:469, ] 
 wbcd_test <- wbcd_n[470:569, ] 

 wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test, cl = wbcd_train_labels, k=1) 
 CrossTable(x = wbcd_test_labels, y = wbcd_test_pred, prop.chisq=FALSE)$t; 

 wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test, cl = wbcd_train_labels, k=5) 
 CrossTable(x = wbcd_test_labels, y = wbcd_test_pred, prop.chisq=FALSE)$t 

 wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test, cl = wbcd_train_labels, k=11) 
 CrossTable(x = wbcd_test_labels, y = wbcd_test_pred, prop.chisq=FALSE)$t 

 wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test, cl = wbcd_train_labels, k=15) 
 CrossTable(x = wbcd_test_labels, y = wbcd_test_pred, prop.chisq=FALSE)$t 

 wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test, cl = wbcd_train_labels, k=21) 
 CrossTable(x = wbcd_test_labels, y = wbcd_test_pred, prop.chisq=FALSE)$t 

 wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test, cl = wbcd_train_labels, k=27) 
 CrossTable(x = wbcd_test_labels, y = wbcd_test_pred, prop.chisq=FALSE)$t 

``` 



 Although the classifier was never perfect, the 1-NN approach was able to avoid some of the false negatives at the expense of adding false positives. 


 It is important to keep in mind, however, that it would be unwise to tailor our approach too closely to our test data; after all, a different set of 100 patient records is likely to be somewhat different from those used to measure our performance. 

#####3. Discuss and explain each improvement separately. Which improvement give the best results?
Z-score standardization is the process of rescaling each feature's values in terms of how many standard deviations they fall from the mean. We use the z-score standardization assuming that future examples will have similar mean and standard deviation as the training examples here.

Testing additional K values allows us to test for the most efficient value of K to produce a small margin of error, when that K value is found we will apply that to future examples under the assumption that it will still continue to produce the smallest margin of error.


